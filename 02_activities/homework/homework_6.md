# Homework 6: Reflecton

- Due on Saturday, September 21 at 11:59pm
- Weight: 8% of total grade

<br>

**Write**: Reflect on your previous work and how you would adjust to include ethics and inequity components. Total length should be a few paragraphs, no more than one page.

About SQL work:
Over the course of these five homewokrs, I learned a lot about SQL and database operations. Starting with basic queries like SELECT and JOIN, I built a solid understanding of how to filter and retrieve data from different tables. As I moved on, I got into more complex functions like COALESCE, ROW_NUMBER(), and UNION, which were new and a bit tricky at first, especially window functions. One of the biggest challenges I faced was with temporary tables; I couldn’t figure out why my code wasn’t running until I realized I needed to DROP the table first. String manipulation and date formatting also caused issues, like when I accidentally used the wrong date format. Later on, I started working with database modifications—using INSERT, DELETE, and UPDATE—and I learned how important it is to avoid duplicate entries when inserting new data. Overall, these assignments taught me a lot, not just about SQL syntax, but also how to troubleshoot and solve problems that come up along the way.

About how I would adjust to include ethics and inequity components:
When working with the farmers' market data, I realized there are some ethical and inequality concerns that need to be addressed. First, regarding privacy, the data contains sensitive information about customers' purchasing habits, and if this data isn’t properly anonymized or is made public, it could potentially violate their privacy. This isn't just a concern for farmers' markets but also applies to other industries like banking, telecommunications, and healthcare, where the exposure of sensitive data can cause serious issues. It’s essential that we ensure data protection to avoid these risks.

Next, there’s the issue of data bias. If the data collection process is biased, or if the models used to analyze the data contain human biases, the outcomes of the analysis will also be biased. For instance, farmers' market data might primarily reflect frequent shoppers while overlooking people who, due to economic or geographical reasons, don’t visit as often. This kind of bias could lead to decisions that ignore the needs of underrepresented groups, like lower-income customers or minorities. In data analysis, bias is a challenge that often surfaces, especially when the data collection itself isn’t fully representative, or when human decisions influence the models.

Additionally, there’s the question of fairness in how the data is used. If decisions about the market’s operations are based on the habits of high-spending customers, the layout or offerings of the market could be tailored to them, leaving lower-spending customers' needs unmet. The use of algorithms could even amplify this inequality by disproportionately focusing on the preferences of higher-income customers.

In conclusion, it’s crucial to be mindful of these privacy, bias, and fairness issues when working with data, not only to protect individuals but also to ensure that decisions based on this data are fair and inclusive.
